{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9da39de-261a-432e-8e64-e52dce51ebf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from os.path import join, basename\n",
    "from scipy.io import savemat\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.transform import resize\n",
    "from skimage.segmentation import expand_labels\n",
    "from skimage.measure import regionprops_table, perimeter, perimeter_crofton\n",
    "from skimage.morphology import remove_small_holes, remove_small_objects\n",
    "from skimage.filters import threshold_otsu, threshold_multiotsu, unsharp_mask\n",
    "\n",
    "from cccode.image import ck\n",
    "from Deeplearning.evaluate import RecognitionAnalyzer\n",
    "from Deeplearning.util.functions import source_from_sample_id, figure_preproduction\n",
    "from Deeplearning.bloodsmear import (outlier_cells_visual, select_outlier_cells, \n",
    "    remove_cells_closed_to_edge, cell_region_properties)\n",
    "\n",
    "WAVELENGTH = 532e-9\n",
    "ProjectRoot = \"D:\\\\Workspace\\\\Blood Recognition\\\\Deeplearning\"\n",
    "FiguresRoot = \"D:\\\\Postgraduate\\\\Investigate\\\\Blood Recognition\\\\figures\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fb6676-3655-46dd-ad65-6646772f792d",
   "metadata": {},
   "source": [
    "### Outlier Cells Extracting for Individual Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f78e19-fc5f-4c29-8453-c418b5ff30bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # The inputs of func 'cell_region_properties' is composed of area labels\n",
    "def outlier_cell_area_mask(image, boxes, indexes=None, otsu_bins=100, expand_distance=6):\n",
    "    # Pick out the boxes of outlier cells\n",
    "    if indexes is not None:\n",
    "        boxes = boxes[indexes]\n",
    "\n",
    "    # Extracting the available area from the given boxes\n",
    "    labeled_mask = np.zeros_like(image)\n",
    "    for lbl, (x, y, w, h, _) in enumerate(boxes):\n",
    "        # notice: the 'lbl' used here is different from the 'label' used in object annotating\n",
    "        # extract available areas from boxes\n",
    "        y_min, y_max = int(y-h/2), int(y+h/2)\n",
    "        x_min, x_max = int(x-w/2), int(x+w/2)\n",
    "        limited_area = image[y_min:y_max, x_min:x_max]\n",
    "        otsu_threshold = threshold_otsu(limited_area, nbins=otsu_bins)\n",
    "        # labeling available areas\n",
    "        y_index, x_index = (limited_area >= otsu_threshold).nonzero()\n",
    "        labeled_mask[y_index+y_min, x_index+x_min] = lbl + 1\n",
    "        \n",
    "    # expanding the extracted areas\n",
    "    expanded_mask = expand_labels(labeled_mask, distance=expand_distance).astype(int)\n",
    "\n",
    "    # Before image area extracting, normalize the image to (0, 1), and amend image\n",
    "    image = (image-np.min(image)) / (np.max(image)-np.min(image))  # Normalize\n",
    "    image = unsharp_mask(image, radius=5, amount=1)                # Unsharp\n",
    "    image = image - np.min(image)\n",
    "    \n",
    "    # Exact cell area extracting\n",
    "    for lbl in range(1, np.max(expanded_mask)+1):\n",
    "        roi = image * (expanded_mask == lbl)\n",
    "        sep_threshold = threshold_otsu(roi)\n",
    "        regions = np.digitize(roi, bins=(np.min(roi), sep_threshold, np.max(roi)))\n",
    "        removed_area = (regions == 1) * (expanded_mask == lbl)\n",
    "        expanded_mask[removed_area] = 0\n",
    "        \n",
    "        # Smoth cell center holes and remove surrounding dots\n",
    "        cur_lbl = expanded_mask == lbl\n",
    "        cur_lbl_restored = remove_small_holes(cur_lbl, 5000)\n",
    "        cur_lbl_restored = remove_small_objects(cur_lbl_restored, 3000).astype(int)\n",
    "        res = cur_lbl - cur_lbl_restored\n",
    "        expanded_mask -= res * lbl\n",
    "    return expanded_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765a3ab-7eec-417c-a2e9-6292b4053e6d",
   "metadata": {},
   "source": [
    "### Load Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b82493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzed_data_fname = 'caches\\\\acc_compare_set202109_1211-141810.pkl'\n",
    "analyzer = RecognitionAnalyzer(join(ProjectRoot, analyzed_data_fname))\n",
    "\n",
    "source_fnames = analyzer.data.get(\"source_fnames\")\n",
    "bsrnet_recognitions = analyzer.data.get(\"BSRNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e661d838-8e6f-4f4f-9011-92ebc9b3acc0",
   "metadata": {},
   "source": [
    "### Cell Properties Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac918af8-83df-4794-a52e-35d3cda2d79b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 122"
     ]
    }
   ],
   "source": [
    "def sample_rescale(image, boxes, scale=10):\n",
    "    image = resize(image, [ax*scale for ax in image.shape])\n",
    "    for i, box in enumerate(boxes):\n",
    "        box = [elm*scale for elm in box]\n",
    "        boxes[i] = box\n",
    "    return image, boxes\n",
    "\n",
    "\n",
    "selected_fnames, phases, labels = [], [], []\n",
    "for i, (fname, boxes) in enumerate(zip(source_fnames, bsrnet_recognitions)):\n",
    "    print(f\"\\r\", i, end=\"\")\n",
    "    phase = source_from_sample_id(basename(fname), \"phase_matrix\")\n",
    "    # Select outlier cells and only focus on rbc\n",
    "    outlier_rbc_indexes = select_outlier_cells(boxes, specified_type_idx=0)\n",
    "    outlier_rbc_indexes = remove_cells_closed_to_edge(boxes, outlier_rbc_indexes, phase.shape)\n",
    "    # Extract rbc cell region properties based on cell coordinates and phase\n",
    "    if len(outlier_rbc_indexes) > 0:\n",
    "        selected_fnames.append(fname)\n",
    "        # outlier_cells_visual(phase, boxes[outlier_rbc_indexes])\n",
    "        # phase, boxes = sample_rescale(phase, boxes)\n",
    "        cells_area_mask = outlier_cell_area_mask(phase, boxes, outlier_rbc_indexes)\n",
    "        # ck.img_show(phase, cells_area_mask)\n",
    "        phases.append(phase)\n",
    "        labels.append(cells_area_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28733c-3448-4030-88d3-6cb35d8437c8",
   "metadata": {},
   "source": [
    "#### Data transfer to Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e76d55c0-693a-42ba-9579-fa2f745ca1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# phase normalize\n",
    "phase = (phase-phase.min())/(phase.max()-phase.min())\n",
    "phase = img_as_ubyte(phase)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "cells_area_mask = img_as_ubyte(cells_area_mask)\n",
    "\n",
    "savemat(join(FiguresRoot, \"statistics\\\\pre10_pha-lbl.mat\"),\n",
    "        {\"phase_pre10\": phases[:10],\n",
    "         \"label_pre10\": labels[:10]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00040e7-ef8c-482a-8f64-cd0653256dbb",
   "metadata": {},
   "source": [
    "#### Cell region properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15730eb-6fb0-44a0-be47-f933c5e43a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PixelSize = 4.8e-6\n",
    "\n",
    "def cell_region_properties(labeled_areas, phase, properties=None) -> dict:\n",
    "    \"\"\" Extract recognized RBC cells with the dominant areas and\n",
    "    produce specified properties into and pandas dict for every phase image.\n",
    "    Returns\n",
    "    -------\n",
    "    properties_tables: list\n",
    "        [properties_table_0: {'area', 'bbox', ...}, properties_table_1, ...] \"\"\"\n",
    "    def volume(image, intensity): return np.sum(intensity * image * PixelSize**2)\n",
    "\n",
    "    def mch(image): return 10 * WAVELENGTH * np.sum(image > 0) / (2 * np.pi * 0.002)\n",
    "\n",
    "    def mean_phase_shift(image, intensity): return np.sum(intensity) / np.sum(image)\n",
    "\n",
    "    def form_factor(image): return 4 * np.pi * np.sum(image) / np.square(perimeter(image, 4))\n",
    "\n",
    "    if not properties:\n",
    "        properties = (\"image\", \"label\", \"area\", \"bbox\", \"eccentricity\", \"perimeter\", \"intensity_image\")\n",
    "    prop_dict = regionprops_table(labeled_areas, \n",
    "                                  intensity_image=phase, \n",
    "                                  properties=properties,\n",
    "                                  extra_properties=(form_factor, volume, mean_phase_shift, mch))\n",
    "    return prop_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e31560cc-f884-4723-b810-b01de4f430ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenchao\\AppData\\Local\\Temp/ipykernel_5712/1700443598.py:16: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  def form_factor(image): return 4 * np.pi * np.sum(image) / np.square(perimeter(image, 4))\n"
     ]
    }
   ],
   "source": [
    "rbc_properites = {}\n",
    "for phase, label in zip(phases, labels):\n",
    "    # Region properties\n",
    "    prop_dict = cell_region_properties(label, phase)\n",
    "    # prop_dict[\"cell_identity\"] = [(fname, idx) for idx in outlier_rbc_indexes]\n",
    "    for k, v in prop_dict.items():\n",
    "        if k not in rbc_properites.keys():\n",
    "            rbc_properites[k] = v\n",
    "        else:\n",
    "            rbc_properites[k] = np.concatenate([rbc_properites[k], v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7371fbca-6dcc-4fcf-89f1-b43a5631f520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./Resourse/UpsampledRBCProps.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rbc_properites, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98ef3412-be07-409e-b8a4-26ee3e244b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cell_collections_visualization(images):\n",
    "    fig, axes = plt.subplots(4, 8, figsize=(16, 8), constrained_layout=True)\n",
    "    for i, img in enumerate(images):\n",
    "        nr, nc = divmod(i, 8)\n",
    "        ax = axes[nr, nc]\n",
    "        ax.imshow(img, cmap=\"gray\")\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        for sp in [\"top\", \"bottom\", \"left\", \"right\"]:\n",
    "            ax.spines[sp].set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "intensitys = rbc_properites[\"image\"]\n",
    "for i in range(len(intensitys)//32):\n",
    "    cell_collections_visualization(intensitys[i*32:(i+1)*32])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d816c64086bec19aa231967d02af10473d96d9078f79c65bf7e02600b0507221"
  },
  "kernelspec": {
   "display_name": "torch18",
   "language": "python",
   "name": "torch18"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
