2021-12-02
average_mini_distance(self.set["average_mini_distance"])
	list: [d0, d1, ..., dn]

distance_indexes
	list: [i0, i1, ..., in]
	getting: np.squeeze(np.argwhere(self.set["average_mini_distance"] < max_distance))
	
inverse_ordered_indexes


[Feature Decoding (in FP)]
The output of Feature Extracting Module is a matrix with shape of 40×40×4×8,
in each grid 3 bounding boxes is predicted. This matrix should be decoded into
real predict results through a Feature Decoding Module. The decoding of
extracted features could be divided into 3 parts:

* Anchor box decoding
  The coordinate predictions in four bounding box is not the real position, but biases for priors.
  Real positions could be calculated as:
    bx = sigmoid(tx) + cx
    by = sigmoid(ty) + cy
    bw = pw * exp(tw)
    bh = ph * exp(th)
  where the (bx, by) is the real position of up-left point for the predicted bounding box,
  and the (bw, bh) is the size of predicted bounding box.

* Confidence decoding
  The confidence decoding is more simply, and could be represented as：
    Conf = sigmoid(t_conf)

* Class decoding
  The class decoding has the same routine as confidence decoding, just cast the predicted
  values using a sigmoid function:
    Score_i = sigmoid(t_score_i)

After the feature decoding, the behavior of final bounding box predicting is different for
the training and evaluating stage:
* Training: All the bounding box exported at the decoding procedure is sending into
  loss function for computing the loss between labels and predictions.
* Evaluating: The bounding box outputs will first be filtered through a CONFIDENCE thresholding,
  all the box has the lower conf value than the threshold will be abandoned. Second, the
  Non-Maximum Suppression will be used to filtering the multiple predictions for single object.

Therefore, 3 procedure should be developed to achieve the processing of extracted features:
Feature decoding, Loss computing and Prediction Filtering (?)
